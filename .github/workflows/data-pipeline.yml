name: Data Pipeline and ETL

on:
  schedule:
    # Run data pipeline daily at 1 AM UTC
    - cron: "0 1 * * *"
  workflow_dispatch:
    inputs:
      data_source:
        description: "Data source to process"
        required: true
        default: "all"
        type: choice
        options:
          - all
          - arxiv
          - pubmed
          - semantic_scholar
      full_refresh:
        description: "Perform full data refresh"
        required: false
        default: false
        type: boolean

jobs:
  data-ingestion:
    name: Data Ingestion
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run data ingestion
        run: |
          python services/ingestion_service/main.py \
            --source ${{ github.event.inputs.data_source || 'all' }} \
            --full-refresh ${{ github.event.inputs.full_refresh || 'false' }}

      - name: Validate ingested data
        run: |
          python services/ingestion_service/validate_data.py

      - name: Upload ingestion logs
        uses: actions/upload-artifact@v4
        with:
          name: ingestion-logs
          path: logs/ingestion/

  data-processing:
    name: Data Processing
    runs-on: ubuntu-latest
    needs: data-ingestion

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Process raw data
        run: |
          python services/ingestion_service/process_data.py

      - name: Generate embeddings
        run: |
          python services/ingestion_service/generate_embeddings.py

      - name: Update search indices
        run: |
          python services/ingestion_service/update_indices.py

  data-quality-check:
    name: Data Quality Check
    runs-on: ubuntu-latest
    needs: data-processing

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install great-expectations

      - name: Run data quality checks
        run: |
          python services/monitoring_service/data_quality_check.py

      - name: Generate data quality report
        run: |
          python services/monitoring_service/generate_report.py

      - name: Upload quality report
        uses: actions/upload-artifact@v4
        with:
          name: data-quality-report
          path: reports/data_quality/
